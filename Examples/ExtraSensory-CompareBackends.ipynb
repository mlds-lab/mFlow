{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Cross-Validation Experiment on the ExtraSensory data set with Backend Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "os.chdir(os.path.abspath('..'))\n",
    "\n",
    "#Disable multi-threading in NumPy \n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\" \n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\" \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import mkl\n",
    "mkl.get_max_threads()\n",
    "mkl.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Blocks.data_loader import extrasensory_data_loader\n",
    "from Blocks.dummy_dataloader import dummy_data_loader\n",
    "from Blocks.filter import MisingLabelFilter,  MisingDataColumnFilter, Take\n",
    "from Blocks.imputer import Imputer\n",
    "from Blocks.normalizer import Normalizer\n",
    "from Blocks.experimental_protocol import ExpTrainTest, ExpCV, ExpWithin\n",
    "from Blocks.results_analysis import ResultsConcat, ResultsCVSummarize, DataYieldReport\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import tree\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Workflow.workflow import workflow\n",
    "import Workflow.compute_graph\n",
    "import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the workflow\n",
    "\n",
    "This workflow performs four train/test experiments on the ExtraSensory data set sleeping prediction task to illustrate the use of different scheduler back ends. The data are loaded once, followed by four parallel copies of the remaining workflow, which includes a column filter that screens out feature dimensions that are less than 20% observed, a missing label filter that removes instances without labels, mean imputation and feature normalization. \n",
    "\n",
    "The demonstration compares the run time of three different workflow scheduler backends:  sequential, multithreaded, and multiprocess. We run the parallel schedulers with 1, 2 and 4 workers. We note that due to communication overhead between the master and worker threads in the multi-process backend, and issues with Python's global interpreter lock in the multi-threaded backend, parallel speedups can be less than linear even for seemingly embarassingly parallel tasks. Parallel speedups also depend on the number of avilable cores. Also note that this demo requires an extended run time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\"LR\": LogisticRegression(solver=\"lbfgs\",max_iter=1000)}\n",
    "metrics    = [accuracy_score, f1_score, precision_score, recall_score]\n",
    "\n",
    "res       = []\n",
    "df_raw    = extrasensory_data_loader(label=\"SLEEPING\");\n",
    "for i in range(2):\n",
    "    df_cf     = MisingDataColumnFilter(df_raw);\n",
    "    df_lf     = MisingLabelFilter(df_cf);\n",
    "    df_imp    = Imputer(df_lf)\n",
    "    df_norm   = Normalizer(df_imp);\n",
    "    res       += ExpTrainTest(df_norm, estimators, metrics=metrics);\n",
    "\n",
    "configs = {\n",
    "             \"sequential\":[1],\n",
    "             \"multithread\":[2],\n",
    "             \"multiprocess_pipeline\":[2]\n",
    "          }\n",
    "\n",
    "results={}\n",
    "for config in configs:\n",
    "    for workers in configs[config]:\n",
    "        \n",
    "        print(config, workers)\n",
    "        flow=workflow(res);        \n",
    "        start = time.time()\n",
    "        output=flow.run(backend=config, num_workers=workers, monitor=True, from_scratch=True);\n",
    "        results[config+\"(%d)\"%(workers)] = time.time()-start\n",
    "        print(config, workers, results[config+\"(%d)\"%(workers)])\n",
    "    \n",
    "time_df = pd.DataFrame(list(results.values()),columns=[\"Time(s)\"], index=list(results.keys()))\n",
    "display(time_df.plot(kind='bar', grid=True, title=\"Backend Runtime Comparison\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
